
<h1 align="center">Mini DataBase Manager</h3>

---

<h3 align="center">ğŸ“š Curso: Database II ğŸ“š</h3>

<div align="center">
    <img src="./images/01.png" alt="Proveedores Cloud" style="width: 100%;">
</div>

<h3>ğŸ‘¨â€ğŸ’» Integrantes</h3>

<div align="center">
    <img src="./images/03.png" alt="Proveedores Cloud" style="width: 100%;">
</div>


<div align="center">

# IndexaciÃ³n y OrganizaciÃ³n de Datos No Estructurados para Datos Multimedia

</div>


ğŸ”— <u><strong><a href="https://deepwiki.com/GinoDazaU/base-de-datos-2-proyecto" target="_blank">
Haz clic aquÃ­ para ver la documentaciÃ³n del proyecto
</a></strong></u>
---

## 1. IntroducciÃ³n

Breve descripciÃ³n del proyecto, motivaciÃ³n y objetivos generales.

- Â¿QuÃ© problema resuelve?
- Â¿QuÃ© funcionalidades principales tiene la aplicaciÃ³n?
- Â¿QuÃ© tipo de datos utiliza (texto, imÃ¡genes, audio)?
- Â¿QuÃ© tecnologÃ­as se emplean?

---

## 2. Arquitectura del Sistema

Diagrama arquitectÃ³nico general del sistema, describiendo los principales mÃ³dulos:

- Preprocesamiento de datos
- ConstrucciÃ³n de Ã­ndices
- MÃ³dulo de consulta
- Interfaz de usuario
- Almacenamiento

Incluir un diagrama de flujo o arquitectura.

---

## 3. Ãndice Invertido Textual

### 3.1. Preprocesamiento

El preprocesamiento aplicado sigue el siguiente flujo:

**TokenizaciÃ³n â†’ EliminaciÃ³n de Stopwords â†’ Stemming â†’ NormalizaciÃ³n**

A continuaciÃ³n se muestra un fragmento del cÃ³digo empleado:

```python
def preprocess(text: str) -> list[str]:
    text = text.lower()
    text = re.sub(r"[^\w\s]", " ", text)
    tokens = word_tokenize(text)
    filtered = [t for t in tokens if t.isalpha() and t not in STOPWORDS]
    return [STEMMER.stem(t) for t in filtered]
```

Este procesamiento se aplica tanto a los documentos como a las consultas para asegurar coherencia en el Ã­ndice.

---

### 3.2. ConstrucciÃ³n del Ãndice

La construcciÃ³n del Ã­ndice se implementa usando una variante del algoritmo **SPIMI (Single-pass In-Memory Indexing)** adaptada para entornos con restricciones de memoria, manteniendo la eficiencia de disco mediante escritura incremental y *streaming merge*.

#### Etapas del Algoritmo

1. **Recorrido de documentos**

   Se recorren todos los registros de la tabla que contienen campos `text`, procesando sus contenidos como un Ãºnico documento textual por fila.

   Para cada documento:
   - Se aplica el preprocesamiento (tokenizaciÃ³n, limpieza, stemming).
   - Se genera una lista de tÃ©rminos normalizados.
   - Se construye un diccionario en memoria con la frecuencia de cada tÃ©rmino por `doc_id`.

2. **Escritura de bloques a disco (SPIMI clÃ¡sico)**

   Cuando el diccionario de tÃ©rminos crece mÃ¡s allÃ¡ de un umbral de memoria (en este caso, 4 KB), se descarga como un **bloque parcial ordenado** en disco:  
   `block_0.pkl`, `block_1.pkl`, ...

   Cada bloque es un diccionario ordenado por tÃ©rmino, que contiene pares:  
   `'term' â†’ {doc_id: frecuencia}`.

   Esto se repite hasta procesar todos los documentos, generando n bloques ordenados.

3. **FusiÃ³n en streaming de bloques (Streaming Merge)**

   Para evitar cargar todos los bloques en memoria, se realiza un merge externo en streaming usando un heap mÃ­nimo.

   - Se abre cada bloque y se crea un iterador ordenado.
   - Se inicializa un heap con el primer tÃ©rmino de cada bloque.
   - Se repite:
     - Extraer el tÃ©rmino mÃ¡s pequeÃ±o del heap.
     - Combinar todos los postings de ese tÃ©rmino que aparezcan al tope de algÃºn bloque.
     - Calcular el peso TF-IDF de cada (term, doc_id) directamente.
     - Acumular las normas parciales por documento.
     - Insertar el resultado directamente en un HeapFile (`inverted_index`).
     - Avanzar los iteradores de los bloques que contribuyeron con ese tÃ©rmino.
     - Reinsertar el nuevo tÃ©rmino al heap (si queda).

   Este procedimiento solo mantiene una lÃ­nea por bloque en memoria al mismo tiempo, permitiendo escalar sin problema.

4. **CÃ¡lculo de normas y escritura**

   Las normas acumuladas de cada documento se convierten en su raÃ­z cuadrada y se almacenan en una segunda tabla `inverted_index_norms` como `(doc_id, norm)`.

5. **ConstrucciÃ³n de Ã­ndices auxiliares**

   Para acelerar la bÃºsqueda de tÃ©rminos, se construyen Ã­ndices hash (`ExtendibleHashIndex`) sobre los campos `term` e `id`.

---

#### Ejemplo Guiado

Supongamos que tenemos una tabla `news` con los siguientes 4 documentos:

| ID | Content                         |
|----|---------------------------------|
| 1  | Trump is a robot                |
| 2  | Trump wins again                |
| 3  | The robot uprising begins       |
| 4  | Robot robot robot attacks Trump |

---

**Paso 1: Preprocesamiento**

DespuÃ©s de aplicar tokenizaciÃ³n, stopwords y stemming:

- doc 1 â†’ ['trump', 'robot']  
- doc 2 â†’ ['trump', 'win']  
- doc 3 â†’ ['robot', 'uprising', 'begin']  
- doc 4 â†’ ['robot', 'robot', 'robot', 'attack', 'trump']

---

**Paso 2: ConstrucciÃ³n de bloques**

Simulemos que el lÃ­mite de memoria permite guardar **solo 3 tÃ©rminos** antes de hacer dump.

**Primer bloque (`block_0.pkl`):**

TÃ©rminos procesados:

- 'trump' â†’ {1:1, 2:1, 4:1}  
- 'robot' â†’ {1:1, 3:1, 4:3}  
- 'win'   â†’ {2:1}  

**Contenido final ordenado de `block_0.pkl`:**

```python 
'robot': {1:1, 3:1, 4:3},  
'trump': {1:1, 2:1, 4:1},  
'win': {2:1}  
```

**Segundo bloque (`block_1.pkl`):**  
Quedan los tÃ©rminos:

- 'uprising' â†’ {3:1}  
- 'begin' â†’ {3:1}  
- 'attack' â†’ {4:1}  

**Contenido final ordenado de `block_1.pkl`:**

```python  
'attack': {4:1},  
'begin': {3:1},  
'uprising': {3:1}  
```

---

**Paso 3: Streaming Merge**

Se abren los bloques en modo iterador y se extrae el primer tÃ©rmino de cada uno.

Inicializamos el heap mÃ­nimo con los primeros tÃ©rminos:

```python 
('attack', 1), ('robot', 0)  
```

Cada entrada es (tÃ©rmino, bloque_id)

**IteraciÃ³n 1:**  
- `min = attack` (bloque 1)  
- Se procesa: `{4:1}`  
- Se calcula su TF-IDF y se escribe en `inverted_index`  
- Avanzar iterador de bloque 1 â†’ siguiente tÃ©rmino: `begin`  
- Nuevo `heap`: `('begin', 1), ('robot', 0) `

**IteraciÃ³n 2:**  
- `min = begin` (bloque 1)  
- Se procesa: `{3:1}`  
- Escribir  
- Avanzar â†’ siguiente: `uprising`  
- Nuevo `heap`: `('robot', 0), ('uprising', 1)`

**IteraciÃ³n 3:**  
- `min = robot` (bloque 0)  
- Se procesa: `{1:1, 3:1, 4:3}`  
- Escribir  
- Avanzar â†’ siguiente: `trump`  
- Nuevo heap: `('trump', 0), ('uprising', 1)` 

**IteraciÃ³n 4:**  
- `min = trump` (bloque 0)  
- Se procesa: `{1:1, 2:1, 4:1}`  
- Escribir  
- Avanzar â†’ siguiente: `win`  
- Nuevo heap: `('uprising', 1), ('win', 0)`

**IteraciÃ³n 5:**  
- min = `uprising` (bloque 1)  
- Se procesa: `{3:1}`  
- Escribir  
- Bloque 1 termina  
- Nuevo heap: `('win', 0)`

**IteraciÃ³n 6:**  
- min = `win` (bloque 0)  
- Se procesa: `{2:1}`  
- Escribir  
- Fin de bloque 0

---

**Resultado Final:**

Se generÃ³ un Ã­ndice invertido en disco con postings TF-IDF ordenados por tÃ©rmino:

**inverted_index:**

```python  
'attack' â†’ [[4, 0.75]]  
'begin' â†’ [[3, 0.75]]  
'robot' â†’ [[1, tfidf], [3, tfidf], [4, tfidf]]  
'trump' â†’ ...  
'uprising' â†’ ...  
'win' â†’ ...  
```

**inverted_index_norms:**

```python
1 â†’ norm1  
2 â†’ norm2  
3 â†’ norm3  
4 â†’ norm4  
```

---

**Notas:**

- Nunca se cargÃ³ un bloque completo a RAM, solo una entrada por vez.
- El heap asegura que el tÃ©rmino mÃ­nimo global estÃ© siempre al frente.
- La salida final estÃ¡ ordenada sin necesidad de postprocesamiento adicional.


---


### Diagrama General

```plaintext
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  HeapFile    â”‚ â† documentos textuales
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
               Preprocesamiento
                      â”‚
                      â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Diccionario en Memoria  â”‚
          â”‚  term â†’ {doc_id: freq}  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚  (lÃ­mite memoria)
                      â–¼
            Dump a disco ordenado
                block_0.pkl, etc.
                      â”‚
                      â–¼
            Streaming Merge con Heap
            TF-IDF + Normas + Write
                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                           â–¼
  inverted_index.dat      inverted_index_norms.dat
```

### 3.3. Consulta

La bÃºsqueda textual se implementa usando el modelo vectorial con similitud de coseno, optimizada para evitar cargar todo el Ã­ndice en memoria.

- **Consulta en lenguaje natural**:  
  El usuario ingresa una frase libre que es preprocesada con los mismos pasos que los documentos: tokenizaciÃ³n, stopwords, stemming y normalizaciÃ³n.

- **Similitud de coseno**:  
  Para cada documento que contiene al menos un tÃ©rmino de la consulta, se calcula la similitud de coseno entre su vector TF-IDF y el de la consulta:

  $$
  \cos(\theta) = \frac{\vec{q} \cdot \vec{d}}{\|\vec{q}\| \cdot \|\vec{d}\|}
  $$

  Donde:  
  - $\vec{q}$ es el vector TF-IDF de la consulta.  
  - $\vec{d}$ es el vector TF-IDF del documento.  
  - $\|\vec{d}\|$ es la norma precalculada del documento.

  Esto permite obtener un ranking de documentos por relevancia semÃ¡ntica.

- **RecuperaciÃ³n Top-K eficiente**:  
  Se usa un Ã­ndice hash extensible para acceder rÃ¡pidamente a los postings de cada tÃ©rmino, evitando recorrer el Ã­ndice completo.  
  Solo los documentos relevantes se mantienen en memoria, permitiendo escalar a grandes colecciones.


---



## 4. IndexaciÃ³n de Datos Multimedia

### 4.1. ExtracciÃ³n de CaracterÃ­sticas

- Descriptores utilizados (e.g., MFCC para audio, ResNet50 para imÃ¡genes)  
- LibrerÃ­as empleadas  

### 4.2. ConstrucciÃ³n del Diccionario Visual / AcÃºstico

- K-Means sobre los descriptores locales  
- Visual/acoustic words  
- RepresentaciÃ³n de cada objeto como histograma  

### 4.3. BÃºsqueda KNN Secuencial

- TF-IDF sobre histogramas  
- Similitud de coseno  
- RecuperaciÃ³n eficiente con heap (Top-K)

### 4.4. BÃºsqueda KNN con IndexaciÃ³n Invertida

- Estructura del Ã­ndice invertido sobre visual/acoustic words  
- AdaptaciÃ³n del modelo textual a dominio multimedia  
- Funcionamiento y optimizaciÃ³n

---

## 5. Interfaz de Usuario

### 5.1. FrontEnd para BÃºsqueda Textual

- Sintaxis de consulta (tipo SQL o personalizada)  
- Ejemplo de uso  
- PresentaciÃ³n de resultados  
- MediciÃ³n de tiempo de respuesta  

### 5.2. FrontEnd para Consultas Multimedia

- Carga de imagen o audio de consulta  
- Resultados visuales con metadatos  
- AsociaciÃ³n con resultados textuales  
- Ejemplo de uso y respuesta

---

## 6. EvaluaciÃ³n y ComparaciÃ³n de DesempeÃ±o

### 6.1. ComparaciÃ³n de BÃºsqueda en Texto

- Consultas equivalentes entre nuestro sistema y PostgreSQL  
- Tiempos de respuesta, precisiÃ³n de resultados  
- TecnologÃ­as usadas por PostgreSQL (GIN, GiST, ts_rank, etc.)

### 6.2. ComparaciÃ³n en BÃºsqueda Multimedia

- ComparaciÃ³n entre KNN secuencial y KNN con Ã­ndice invertido  
- Tiempo de ejecuciÃ³n y escalabilidad  
- ComparaciÃ³n con herramientas externas (pgVector, Faiss)  
- DiscusiÃ³n sobre la maldiciÃ³n de la dimensionalidad

### 6.3. Resultados

- Tablas comparativas  
- GrÃ¡ficos de rendimiento  
- AnÃ¡lisis crÃ­tico

- Tiempo de consulta 8nn:

## â± ComparaciÃ³n de rendimiento: KNN Secuencial vs. KNN Indexado

| N canciones | Tiempo KNN Secuencial (s) | Tiempo KNN Indexado (s) |
|-------------|----------------------------|--------------------------|
| 60          | 1.3                        | 0.9                      |
| 1,000       | 21.7                       | 2.3                      |
| 2,000       | 43.3                       | 3.1                      |
| 4,000       | 86.7                       | 4.5                      |
| 8,000       | 173.3                      | 6.8                      |
| 16,000      | 346.7                      | 9.4                      |
| 32,000      | 693.3                      | 13.5                     |
| 64,000      | 1386.7                     | 18.9                     |

---

## 7. Datasets Utilizados

- Nombre del dataset  
- Fuente (Kaggle, GitHub, etc.)  
- DescripciÃ³n del contenido  
- NÃºmero de registros / imÃ¡genes / audios

---

## 9. Repositorio y EjecuciÃ³n

### 9.1. Requisitos del Sistema

- Python / versiones  
- NextJS / dependencias  

### 9.2. Instrucciones de EjecuciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/GinoDazaU/base-de-datos-2-proyecto.git
cd base-de-datos-2-proyecto
```


# Inicia el backend

Instalar las dependencias

```bash
pip install -r requirements.txt
```

Ejecutar la aplicacion

```bash
 python .\backend\api\main.py

```

# Iniciar el frontend

Ingresar al directorio de frontend

```bash
cd frontend
```

Crear un archivo `.env` con el siguiente contenido

```bash
NEXT_PUBLIC_BACK_API_URL=http://localhost:8000
```

Instalar las dependencias
```bash
npm install
```

Ejecutar la aplicacion
```bash
npm run dev
```

## 10. VisualizaciÃ³n de frontend


Disponemos de un panel donde agregar los audios visualizarlos

<div align="center">
    <img src="./images/05.jpg" alt="Proveedores Cloud" style="width: 100%;">
</div>

Podemos aÃ±adir mas archivos de audio a la colecciÃ³n, que seran usadas para las consultas 

<div align="center">
    <img src="./images/06.jpg" alt="Proveedores Cloud" style="width: 100%;">
</div>

Cada consulta retorna una tabla donde si es un archivo de audio podremos reproducirlo 

<div align="center">
    <img src="./images/07.jpg" alt="Proveedores Cloud" style="width: 100%;">
</div>

De la misma forma podremos abrir todo el contenido de un campo textual para su verificaciÃ³n.

<div align="center">
    <img src="./images/08.jpg" alt="Proveedores Cloud" style="width: 100%;">
</div>

